{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic modeling for restaurant success/failure based on current attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics \n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in neigbhor and census features.\n",
    "# Excludes restaurants that opened after 2015 (can't meet our def of success)\n",
    "rest_df = pd.read_csv('./spatial/data/business_neighbors_census_atts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge in Ryan's restaurant attributes\n",
    "att_df = pd.read_pickle('./data/restaurants_imputed.pkl.bz2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "att_df = att_df.loc[:, att_df.columns.str.startswith(r'biz')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rest_df = rest_df.merge(att_df, on='business_id', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prep for training, eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set input cols to exclude business ID and the actual success statistics. \n",
    "# Can be modified more to test different variable combinations\n",
    "non_input_cols = np.array(['business_id', 'is_open', 'successful', 'stars', 'review_count'])\n",
    "input_cols = rest_df.columns[np.isin(rest_df.columns.values, non_input_cols, invert=True)]\n",
    "X = rest_df[input_cols].values\n",
    "y = rest_df['successful'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hold out test set for final test. Use cross val for development\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .2, random_state=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for cross validation testing and var imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_cross_val(pipeline, X, y):\n",
    "    cv_scores = cross_val_score(pipeline, X_train, y_train, cv=5, scoring='f1_weighted')\n",
    "    print('Cross Val Scores: {}'.format(cv_scores))\n",
    "    print('CV Mean F1: {}'.format(np.mean(cv_scores)))\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def var_imp_plot(var_imps, input_col_names, topn=10):\n",
    "    indices = np.argsort(var_imps)[::-1]\n",
    "    indices = indices[0:topn+1]\n",
    "    # Print the feature ranking\n",
    "    print(\"Feature ranking:\")\n",
    "    \n",
    "    input_col_sorted = input_col_names.values[indices]\n",
    "    for i in range(indices.shape[0]):\n",
    "        print('{}: {}'.format(input_col_sorted[i], round(var_imps[indices[i]], 3)))\n",
    "        \n",
    "    # Plot the feature importances of the forest\n",
    "    plt.figure()\n",
    "    plt.title(\"Feature importances\")\n",
    "    plt.barh(np.flip(input_col_sorted), np.flip(var_imps[indices]),\n",
    "           color=\"r\", align=\"center\")\n",
    "    plt.show()\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training/CrossVal/VarImp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogReg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "lr_c = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "lr_pipeline = Pipeline([('scale', scaler), ('clf', lr_c)])\n",
    "pipeline_cross_val(lr_pipeline, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable importance\n",
    "lr_pipeline.fit(X_train, y_train)\n",
    "lr_varimp = lr_pipeline.steps[1][1].coef_\n",
    "var_imp_plot(lr_varimp[0], input_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_c = RandomForestClassifier(n_estimators=200, random_state=25, min_samples_leaf=1)\n",
    "rf_pipeline = Pipeline([('clf', rf_c)])\n",
    "pipeline_cross_val(rf_pipeline, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pipeline.fit(X_train, y_train)\n",
    "rf_varimp = rf_pipeline.steps[0][1].feature_importances_\n",
    "var_imp_plot(rf_varimp, input_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_c = SVC(gamma='auto', kernel='rbf')\n",
    "svm_pipeline = Pipeline([('scale', scaler), ('clf', svm_c)])\n",
    "pipeline_cross_val(svm_pipeline, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_c = GaussianNB()\n",
    "nb_pipeline = Pipeline([('clf', nb_c)])\n",
    "pipeline_cross_val(nb_pipeline, X_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
