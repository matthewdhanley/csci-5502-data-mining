{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Census Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from osgeo import ogr, osr\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biz_att_df = pd.read_csv('./data/business_neighbors_atts_new.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Counties and Zip Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geometry = [Point(xy) for xy in zip(biz_att_df.longitude, biz_att_df.latitude)]\n",
    "crs = {'init': 'epsg:4326'} #http://www.spatialreference.org/ref/epsg/2263/\n",
    "geo_df = gpd.GeoDataFrame(biz_att_df, crs=crs, geometry=geometry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get county based on lat lon\n",
    "counties = gpd.read_file('data/counties/tl_2017_us_county.shp')\n",
    "counties.crs = crs\n",
    "counties.columns = [x.lower() for x in counties.columns]\n",
    "# Rename column\n",
    "counties.rename(columns={'countyfp':'fipscty'}, inplace=True)\n",
    "# Get county of each.\n",
    "geo_df = gpd.sjoin(geo_df, counties[['fipscty', 'geometry']], op='intersects', how='inner')\n",
    "geo_df['fipscty'] = geo_df['fipscty'].apply(int)\n",
    "geo_df.drop('index_right', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zipcodes = gpd.read_file('data/zipcodes/v104/zip_poly.gdb')\n",
    "zipcodes = zipcodes.loc[zipcodes['STATE']=='NV']\n",
    "zipcodes.columns = [x.lower() for x in zipcodes.columns]\n",
    "zipcodes.rename(columns={'zip_code':'zipcode'}, inplace=True)\n",
    "zipcodes.crs = crs\n",
    "geo_df = gpd.sjoin(geo_df, zipcodes[['zipcode', 'geometry', 'pop_sqmi']], op='intersects',how='inner')\n",
    "geo_df['zipcode'] = geo_df['zipcode'].apply(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Census Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_county_data(df, year):\n",
    "    cnty_df = pd.read_csv('data/census/cbp{}co.csv'.format(year))\n",
    "    # Limit to restaurants only, naics codes:https://www.naics.com/six-digit-naics/?code=72\n",
    "    cnty_df = cnty_df.loc[cnty_df['naics'] == '722///']\n",
    "    # Drop unimportant columns\n",
    "    cnty_keeplist = ['fipscty', 'emp', 'qp1', 'ap', 'est', 'n1_4', 'n5_9', \n",
    "                     'n10_19', 'n20_49', 'n50_99', 'n100_249', 'n500_999', 'n1000']\n",
    "    cnty_df = cnty_df[cnty_keeplist]\n",
    "    cnty_df.columns = ['cn_y{}_{}'.format(year, x) for x in cnty_df.columns]\n",
    "    cnty_df.rename(columns={'cn_y{}_fipscty'.format(year):'fipscty'}, inplace=True)\n",
    "    return df.merge(cnty_df, on='fipscty')\n",
    "\n",
    "def add_zip_data(df, year):\n",
    "    # NOT ALL RESTAURANTS HAVE A MATCHING ZIP\n",
    "    zip_df = pd.read_csv('data/census/zbp{}detail.csv'.format(year))\n",
    "    # Limit to restaurants only, naics codes:https://www.naics.com/six-digit-naics/?code=72\n",
    "    zip_df = zip_df.loc[zip_df['naics'] == '72----'] # Just doing all hospitality for now\n",
    "    # Drop unimportant columns\n",
    "    zip_keeplist = ['zip', 'est', 'n1_4', 'n5_9', \n",
    "                    'n10_19', 'n20_49', 'n50_99', 'n100_249', 'n500_999', 'n1000']\n",
    "    zip_df = zip_df[zip_keeplist]\n",
    "    zip_df.columns = ['cn_y{}_zip_{}'.format(year, x) for x in zip_df.columns]\n",
    "    zip_df.rename(columns={'cn_y{}_zip_zip'.format(year):'zipcode'}, inplace=True)\n",
    "    return df.merge(zip_df, on='zipcode', how='left')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_list = [str(y).zfill(2) for y in range(4,17)]\n",
    "for y in year_list:\n",
    "    geo_df = add_county_data(geo_df, y)\n",
    "    geo_df = add_zip_data(geo_df, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing zipcodes. There are 62 biz's in 89158 and there's not census data at all for that.\n",
    "# Also 2 biz's in 89161, no census data.\n",
    "# We'll have to interpolate or just forget it\n",
    "zip_df = pd.read_csv('data/census/zbp05detail.csv')\n",
    "geo_df['zipcode'].unique()[np.isin(geo_df['zipcode'].unique(), zip_df['zip'].unique(), invert=True)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fill missing zip data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using simple mean filling\n",
    "census_cols = geo_df.columns.str.startswith('cn')\n",
    "geo_df.loc[:, census_cols] = geo_df.loc[:, census_cols].fillna(geo_df.loc[:, census_cols].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Year-year diffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_year_diffs(df, year):\n",
    "    \"\"\"Add year-to-year diffs as percentage growth/decrease\"\"\"\n",
    "    census_cols_suffixes = ['emp', 'qp1', 'ap', 'est', 'n1_4', 'n5_9',\n",
    "       'n10_19', 'n20_49', 'n50_99', 'n100_249',\n",
    "       'n500_999', 'n1000', 'zip_est', 'zip_n1_4',\n",
    "       'zip_n5_9', 'zip_n10_19', 'zip_n20_49', 'zip_n50_99',\n",
    "       'zip_n100_249', 'zip_n500_999', 'zip_n1000']\n",
    "    year = str(year).zfill(2)\n",
    "    prev_year = str(int(year) - 1).zfill(2)\n",
    "    for col in census_cols_suffixes:\n",
    "        new_col = 'cn_y{}_diff_{}'.format(year, col)\n",
    "        prev_vals = df['cn_y{}_{}'.format(prev_year, col)].copy()\n",
    "        prev_vals[prev_vals==0] = 1\n",
    "        df[new_col] = 100*((df['cn_y{}_{}'.format(year, col)] - df['cn_y{}_{}'.format(prev_year, col)])/\n",
    "                        prev_vals)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for y in year_list[1:]:\n",
    "    geo_df = add_year_diffs(geo_df, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract year specific data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_df_backup = geo_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_df = geo_df_backup.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "success_df = pd.read_csv('./data/business_success_long.csv')\n",
    "success_df['first_review'] = pd.to_datetime(success_df.first_review, format='%Y-%m-%d %H:%M:%S')\n",
    "success_df.drop(['stars', 'is_open'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge and get open year\n",
    "geo_df = geo_df.merge(success_df, on='business_id')\n",
    "geo_df = geo_df.loc[geo_df['first_review'].dt.year <= 2015]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate random years for testing\n",
    "# geo_df['open_year'] = np.random.randint(2005, 2016, geo_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_open_year_data(df):\n",
    "    census_cols_suffixes = ['emp', 'qp1', 'ap', 'est', 'n1_4', 'n5_9',\n",
    "   'n10_19', 'n20_49', 'n50_99', 'n100_249',\n",
    "   'n500_999', 'n1000', 'zip_est', 'zip_n1_4',\n",
    "   'zip_n5_9', 'zip_n10_19', 'zip_n20_49', 'zip_n50_99',\n",
    "   'zip_n100_249', 'zip_n500_999', 'zip_n1000']\n",
    "    df['open_year_str'] = df['first_review'].dt.year.apply(str).str.replace('20', '')\n",
    "    for col in census_cols_suffixes:\n",
    "        df['cn_opyear_{}'.format(col)] = [r[1]['cn_y{}_{}'.format(r[1]['open_year_str'],col)] for r in df.iterrows()]\n",
    "        df['cn_opyear_diff_{}'.format(col)] =[r[1]['cn_y{}_diff_{}'.format(r[1]['open_year_str'],col)] for r in df.iterrows()]\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = extract_open_year_data(geo_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cutdown and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop non-target year data\n",
    "final_df.drop(final_df.columns[final_df.columns.str.startswith('cn_y')], inplace=True, axis=1)\n",
    "final_df.columns\n",
    "useful_cols = ['business_id'] +  \\\n",
    "    list(final_df.columns.values[final_df.columns.str.startswith('nn')]) +\\\n",
    "    list(final_df.columns.values[final_df.columns.str.startswith('cn')])\n",
    "print(useful_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "useful_cols = ['business_id', 'is_open', 'successful', 'stars', 'review_count', 'pop_sqmi', 'nn_count', 'nn_percent_rest', 'nn_all_percent_open',\n",
    "               'nn_max_cat_sim', 'nn_min_cat_sim', 'nn_avg_stars', 'nn_max_stars',\n",
    "               'nn_min_stars', 'nn_avg_review_count', 'nn_max_review_count', \n",
    "               'nn_min_review_count', 'nn_rest_avg_stars', 'nn_rest_max_stars', \n",
    "               'nn_rest_min_stars', 'nn_rest_avg_review_count', 'nn_rest_max_review_count', \n",
    "               'nn_rest_min_review_count', 'nn_weighted_avg_stars', 'nn_weighted_avg_review_count', \n",
    "               'nn_weighted_sum_stars', 'nn_weighted_sum_review_count', 'nn_rest_percent_open', 'nn_mean_cat_sim', \n",
    "               'cn_opyear_emp', 'cn_opyear_qp1', 'cn_opyear_ap', 'cn_opyear_est', 'cn_opyear_zip_est',\n",
    "               'cn_opyear_diff_emp', 'cn_opyear_diff_qp1', 'cn_opyear_diff_ap', 'cn_opyear_diff_est', 'cn_opyear_diff_zip_est']\n",
    "cutdown_df = final_df[useful_cols]\n",
    "cutdown_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing NN data\n",
    "nn_cols = cutdown_df.columns[cutdown_df.columns.str.startswith('nn_')]\n",
    "cutdown_df.loc[:, nn_cols] = cutdown_df.loc[:, nn_cols].fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutdown_df.to_csv('./data/business_neighbors_census_atts.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatter_bfit(x, y, title, xlabel, ylabel, xlims=None, ylims=None):\n",
    "    plt.figure(figsize=(8,8), facecolor='white')\n",
    "    plt.scatter(x, y, alpha=0.25)\n",
    "    plt.tick_params(axis='both', which='major', labelsize=12)\n",
    "    m, b = np.polyfit(x, y, 1)\n",
    "    if xlims != None:\n",
    "        plt.xlim(xlims[0], xlims[1])\n",
    "    else:\n",
    "        xlims = (np.min(x), np.max(x))\n",
    "    if ylims != None:\n",
    "        plt.ylim(ylims[0], ylims[1])\n",
    "    \n",
    "    plt_x = np.arange(xlims[0], xlims[1], (xlims[1]-xlims[0])/len(x))\n",
    "    plt.plot(plt_x, m*plt_x + b, '--', linewidth=2.5, color='orange')\n",
    "    \n",
    "    # Labels\n",
    "    plt.title(title, size=20)\n",
    "    plt.xlabel(xlabel, size=16)\n",
    "    plt.ylabel(ylabel, size=16)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutdown_df = pd.read_csv('./data/business_neighbors_census_atts.csv')\n",
    "scatter_bfit(cutdown_df.cn_opyear_diff_zip_est, \n",
    "             cutdown_df.successful, 'foo',\n",
    "            'bar', 'Rating',ylims=[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
