{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Required packages\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "from multiprocessing import cpu_count\n",
    "from helper_files import *\n",
    "import pickle\n",
    "from scipy.linalg import svd\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Reads in text of reviews and makes a word2vec embedding of all the words\n",
    "directory = \"reviews_3mo\"\n",
    "data = read_reviews(directory) #We only want the review text\n",
    "num_cores = cpu_count()\n",
    "model = Word2Vec(data, size = 50, window = 5, min_count = 1, workers = num_cores)\n",
    "model.save('word2vec_test.model')\n",
    "model.wv.save('wordvecs_test.kv') #Save keyed vectors as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Functions for extracting keywords from a corpus\n",
    "def gen_keywordValues(data):\n",
    "    word_list = []\n",
    "    for i,r in enumerate(data):\n",
    "        for word in r:\n",
    "            if word not in word_list:\n",
    "                word_list.append(word)\n",
    "    \n",
    "    W = np.zeros((len(data), len(word_list)))\n",
    "    for i,r in enumerate(data):\n",
    "        for j,word in enumerate(r):\n",
    "            W[i][j] = W[i][j]+1\n",
    "    return(W,data,word_list)\n",
    "\n",
    "def keyword_extraction(data, t = 5, k = 2):\n",
    "    W,sentences,word_list = gen_keywordValues(data)\n",
    "    if(k >= len(sentences)):\n",
    "        k = len(sentences)\n",
    "    if(t >= len(word_list)):\n",
    "        t = len(word_list)\n",
    "    u,s,v = svd(W)\n",
    "    index = np.argmax(s)\n",
    "    u = u[:,index]\n",
    "    v = v[index,:]\n",
    "    if all(i <= 0 for i in u): u = u*-1\n",
    "    if all(i <= 0 for i in v): v = v*-1\n",
    "    u_ind = np.argsort(u)\n",
    "    v_ind = np.argsort(v)\n",
    "    return([(word_list[w], v[w]) for w in v_ind[-t:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reads in text of reviews and saves a pickle file for each business containing a list of their keywords and weights\n",
    "directory = \"reviews_3mo\"\n",
    "results = read_dir(directory)\n",
    "for r in results:\n",
    "    business_id = r[1]\n",
    "    data = r[0]\n",
    "    print(\"Starting File: \"+business_id)\n",
    "    keywords = keyword_extraction(data)\n",
    "    filename = business_id + \"_keywords.pkl\"\n",
    "    with open(\"keywords/\"+filename,'wb') as f:\n",
    "        pickle.dump(keywords,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Code for converting keywords to vector\n",
    "def create_vec(filename,kv):\n",
    "    with open(filename,'rb') as f:\n",
    "        keywords = pickle.load(f)\n",
    "    keywords = keywords\n",
    "    weights = [w[1] for w in keywords]\n",
    "    norm = np.linalg.norm(weights)\n",
    "    weights = weights/norm\n",
    "    vec = []\n",
    "    for k in keywords:\n",
    "        word = k[0]\n",
    "        if any(vec):\n",
    "            vec = vec+ kv[word]\n",
    "        else:\n",
    "            vec = kv[word]\n",
    "    return(vec)\n",
    "\n",
    "def get_vecs(directory,kv_name):\n",
    "    dic = {}\n",
    "    kv = KeyedVectors.load(kv_name, mmap = 'r')\n",
    "    for filename in os.listdir(directory):\n",
    "        ind = filename.find('_keywords.pkl')\n",
    "        business_id = filename[0:ind]\n",
    "        file = directory + \"/\" + filename\n",
    "        vec = create_vec(file,kv)\n",
    "        dic.update({business_id:vec})\n",
    "    df = pd.DataFrame.from_dict(dic)\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"keywords\"\n",
    "kv_name = \"wordvecs_test.kv\"\n",
    "df = get_vecs(directory,kv_name)\n",
    "file = input('Please input path/filename for vector embedding dataframe file: ')\n",
    "with open(file,'wb') as f:\n",
    "    pickle.dump(df,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Visualize word embeddings\n",
    "word_vecs = KeyedVectors.load('wordvecs_test.kv')\n",
    "words = word_vecs.vocab\n",
    "X = word_vecs[words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=2)\n",
    "X_tsne = tsne.fit_transform(X)\n",
    "tsne_df = pd.DataFrame(X_tsne, index=words, columns=['x', 'y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_list = ['japanese', 'pizza', 'sushi', 'italian', 'mexican', 'chinese', 'delicious', 'cheap', 'expensive', 'car',\n",
    "             'bike', 'clean', 'quick', 'forever', 'wait', 'taste', 'burger', 'dog']\n",
    "ind = [words.index(w) for w in word_list]\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "ax.scatter(tsne_df['x'][ind], tsne_df['y'][ind])\n",
    "for word in word_list:\n",
    "    ax.annotate(word, df['x'][words.index(word)])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for word in word_list:\n",
    "    sim = word_vecs.most_similar(positive = word)\n",
    "    print(word)\n",
    "    print(sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get ratings for TSNE OF keyword embeddings\n",
    "directory = 'reviews_3mo'\n",
    "data = read_dir(directory)\n",
    "ratings = {}\n",
    "for d in data:\n",
    "    business_id = d[1]\n",
    "    rating = float(d[2])\n",
    "    ratings.update({business_id:rating})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Visualize tsne of keyword embeddings\n",
    "with open('word2vec_keywordEmbeddings.pkl') as f:\n",
    "    data = pickle.load(f)\n",
    "cols = list(data.columns)\n",
    "X = data[cols]\n",
    "c = [ratings[c] for c in cols]\n",
    "tsne = TSNE(n_components = 2)\n",
    "X_tsne = tsne.fit_transform(X)\n",
    "tsne_df1 = pd.DataFrame(X_tsne,columns = ['x','y'])\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "plot = ax.scatter(tsne_df1['x'],tsne_df1['y'], c = c)\n",
    "plt.colorbar(plot)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
